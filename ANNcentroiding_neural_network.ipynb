{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BDxGEezuPK29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7d16490b-abd5-4135-b04f-6d820c63f4d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==2.5.0\n",
            "  Downloading tensorflow-2.5.0-cp39-cp39-manylinux2010_x86_64.whl (454.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.4/454.4 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy~=1.19.2\n",
            "  Downloading numpy-1.19.5-cp39-cp39-manylinux2010_x86_64.whl (14.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.9/14.9 MB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.5.0) (2.12.1)\n",
            "Collecting tensorflow-estimator<2.6.0,>=2.5.0rc0\n",
            "  Downloading tensorflow_estimator-2.5.0-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.4/462.4 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.5.0) (0.4.0)\n",
            "Collecting keras-nightly~=2.5.0.dev\n",
            "  Downloading keras_nightly-2.5.0.dev2021032900-py2.py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m56.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting flatbuffers~=1.12.0\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Collecting six~=1.15.0\n",
            "  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
            "Collecting termcolor~=1.1.0\n",
            "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.5.0) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.5.0) (3.20.3)\n",
            "Collecting h5py~=3.1.0\n",
            "  Downloading h5py-3.1.0-cp39-cp39-manylinux1_x86_64.whl (4.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-extensions~=3.7.4\n",
            "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
            "Collecting wrapt~=1.12.1\n",
            "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting absl-py~=0.10\n",
            "  Downloading absl_py-0.15.0-py3-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.0/132.0 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.5.0) (1.6.3)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.5.0) (0.2.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.5.0) (0.40.0)\n",
            "Collecting keras-preprocessing~=1.1.2\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting grpcio~=1.34.0\n",
            "  Downloading grpcio-1.34.1-cp39-cp39-manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m82.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (2.2.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (0.7.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (2.27.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (2.17.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (67.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.9/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (1.0.0)\n",
            "Collecting tensorboard~=2.5\n",
            "  Downloading tensorboard-2.12.0-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m75.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboard-data-server<0.7.0,>=0.6.0\n",
            "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m66.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
            "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (3.4.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0) (5.3.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5.0) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow==2.5.0) (6.1.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0) (2.0.12)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.5->tensorflow==2.5.0) (2.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.5->tensorflow==2.5.0) (3.15.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5.0) (3.2.2)\n",
            "Building wheels for collected packages: termcolor, wrapt\n",
            "  Building wheel for termcolor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4845 sha256=81706a45744046c633aadfdd5d3af5ab1bef8093e6a1f66f3533bc8b724dfc98\n",
            "  Stored in directory: /root/.cache/pip/wheels/b6/0d/90/0d1bbd99855f99cb2f6c2e5ff96f8023fad8ec367695f7d72d\n",
            "  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wrapt: filename=wrapt-1.12.1-cp39-cp39-linux_x86_64.whl size=75968 sha256=d421e71207da65d7bc55b2fe2eaa6a286d4943e9683219b6be33c6238c087d81\n",
            "  Stored in directory: /root/.cache/pip/wheels/98/23/68/efe259aaca055e93b08e74fbe512819c69a2155c11ba3c0f10\n",
            "Successfully built termcolor wrapt\n",
            "Installing collected packages: wrapt, typing-extensions, termcolor, tensorflow-estimator, keras-nightly, flatbuffers, tensorboard-data-server, six, numpy, keras-preprocessing, h5py, grpcio, absl-py, google-auth-oauthlib, tensorboard, tensorflow\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.14.1\n",
            "    Uninstalling wrapt-1.14.1:\n",
            "      Successfully uninstalled wrapt-1.14.1\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "  Attempting uninstall: termcolor\n",
            "    Found existing installation: termcolor 2.2.0\n",
            "    Uninstalling termcolor-2.2.0:\n",
            "      Successfully uninstalled termcolor-2.2.0\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.12.0\n",
            "    Uninstalling tensorflow-estimator-2.12.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.12.0\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 23.3.3\n",
            "    Uninstalling flatbuffers-23.3.3:\n",
            "      Successfully uninstalled flatbuffers-23.3.3\n",
            "  Attempting uninstall: tensorboard-data-server\n",
            "    Found existing installation: tensorboard-data-server 0.7.0\n",
            "    Uninstalling tensorboard-data-server-0.7.0:\n",
            "      Successfully uninstalled tensorboard-data-server-0.7.0\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.16.0\n",
            "    Uninstalling six-1.16.0:\n",
            "      Successfully uninstalled six-1.16.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.22.4\n",
            "    Uninstalling numpy-1.22.4:\n",
            "      Successfully uninstalled numpy-1.22.4\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.8.0\n",
            "    Uninstalling h5py-3.8.0:\n",
            "      Successfully uninstalled h5py-3.8.0\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.53.0\n",
            "    Uninstalling grpcio-1.53.0:\n",
            "      Successfully uninstalled grpcio-1.53.0\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 1.4.0\n",
            "    Uninstalling absl-py-1.4.0:\n",
            "      Successfully uninstalled absl-py-1.4.0\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.0.0\n",
            "    Uninstalling google-auth-oauthlib-1.0.0:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.0.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.12.1\n",
            "    Uninstalling tensorboard-2.12.1:\n",
            "      Successfully uninstalled tensorboard-2.12.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.12.0\n",
            "    Uninstalling tensorflow-2.12.0:\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/usr/local/lib/python3.9/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/usr/local/lib/python3.9/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras==2.4.3\n",
            "  Downloading Keras-2.4.3-py2.py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.9/dist-packages (from keras==2.4.3) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.9/dist-packages (from keras==2.4.3) (1.10.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.9/dist-packages (from keras==2.4.3) (3.1.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.9/dist-packages (from keras==2.4.3) (6.0)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/usr/local/lib/python3.9/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling collected packages: keras\n",
            "  Attempting uninstall: keras\n",
            "\u001b[33m    WARNING: Ignoring invalid distribution -ensorflow (/usr/local/lib/python3.9/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m    Found existing installation: keras 2.12.0\n",
            "    Uninstalling keras-2.12.0:\n",
            "      Successfully uninstalled keras-2.12.0\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/usr/local/lib/python3.9/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mSuccessfully installed keras-2.4.3\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-0bbf01efbf36>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConv2DTranspose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMaxPool2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUpSampling2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mReshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCropping2D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow.keras' has no attribute 'backend'"
          ]
        }
      ],
      "source": [
        "#install keras and tensorflow \n",
        "!pip install tensorflow==2.5.0\n",
        "!pip install keras==2.4.3\n",
        "\n",
        "\n",
        "import os\n",
        "import time\n",
        "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" # Assign which GPU to run on, \"0\" or \"1\"\n",
        "import tensorflow as tf\n",
        "import scipy.io as sio\n",
        "from tensorflow import keras\n",
        "tf.keras.backend.clear_session()\n",
        "import numpy as np\n",
        "from tensorflow.python.keras.layers import Input, Dense, Conv2D, Conv2DTranspose, MaxPool2D, UpSampling2D, concatenate, Flatten, Reshape, Cropping2D\n",
        "from tensorflow.python.keras.models import Model\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "# !unzip \"/content/training_data.zip\" -d \"/content\"\n",
        "\n",
        "!nvidia-smi\n",
        "tf.test.gpu_device_name()\n",
        "\n",
        "\n",
        "Training_Dataset_path_centroid = \"/content/gdrive/MyDrive/MPhys Project/centroid/run_27/centroid.mat\"\n",
        "Training_Dataset_path_gaussfilt = \"/content/gdrive/MyDrive/MPhys Project/centroid/run_27/gaussfilt.mat\"\n",
        "checkpoint_path = \"/content/gdrive/MyDrive/MPhys Project/centroid/run_27\"\n",
        "\n",
        "\n",
        "# set the number of epochs\n",
        "Nepochs = 500\n",
        "\n",
        "# load the training data\n",
        "X = sio.loadmat(Training_Dataset_path_centroid)\n",
        "X = X['images_sampled_mat']\n",
        "# X = X['single_image']\n",
        "X = np.swapaxes(X, 0, -1)\n",
        "X = np.swapaxes(X, 1, 2)\n",
        "X = np.reshape(X, (X.shape[0], X.shape[1], X.shape[2], 1))\n",
        "\n",
        "X_blur = sio.loadmat(Training_Dataset_path_gaussfilt)\n",
        "X_blur = X_blur['images_gaussfilt_mat']\n",
        "\n",
        "X_blur = np.swapaxes(X_blur, 0, -1)\n",
        "X_blur = np.swapaxes(X_blur, 1, 2)\n",
        "X_blur = np.reshape(X_blur, (X.shape[0], X.shape[1], X.shape[2], 1))\n",
        "\n",
        "\n",
        "# set training/validation split\n",
        "X = X[:1500]\n",
        "X_blur = X_blur[:1500]\n",
        "X_training = X[150:]\n",
        "X_training_blur = X_blur[150:]\n",
        "X_validation = X[:150]\n",
        "X_validation_blur = X_blur[:150]\n",
        "\n",
        "\n",
        "# model\n",
        "def create_model():\n",
        "    UB = True\n",
        "    w = 5\n",
        "    inputs = Input((48,48,1))\n",
        "    conv1 = Conv2D(64, (w,w), padding='same', activation=tf.nn.relu,use_bias=UB)(inputs)\n",
        "    pool1 = MaxPool2D((2,2), padding='same')(conv1)\n",
        "\n",
        "    conv2 = Conv2D(128, (w,w), padding='same', activation=tf.nn.relu,use_bias=UB)(pool1)\n",
        "    pool2 = MaxPool2D((2,2), padding='same')(conv2)\n",
        "\n",
        "    conv3 = Conv2D(256, (w,w), padding='same', activation=tf.nn.relu,use_bias=UB)(pool2)\n",
        "    pool3 = MaxPool2D((2,2), padding='same')(conv3)\n",
        "\n",
        "    conv4 = Conv2D(512, (w,w), padding='same', activation=tf.nn.relu,use_bias=UB)(pool3)\n",
        "    pool4 = MaxPool2D((2,2), padding='same')(conv4)\n",
        "\n",
        "    conv5 = Conv2D(1024, (w,w), padding='same', activation=tf.nn.relu,use_bias=UB)(pool4)\n",
        "\n",
        "    deconv4 = Conv2DTranspose(512, (w,w), padding='same', activation=tf.nn.relu, strides=(2,2),use_bias=UB)(conv5)\n",
        "    merge4 = concatenate([conv4,deconv4], axis = 3)\n",
        "\n",
        "    deconv3 = Conv2DTranspose(256, (w,w), padding='same', activation=tf.nn.relu, strides=(2,2),use_bias=UB)(merge4)\n",
        "    merge3 = concatenate([conv3,deconv3], axis = 3)\n",
        "\n",
        "\n",
        "    deconv2 = Conv2DTranspose(128, (w,w), padding='same', activation=tf.nn.relu, strides=(2,2),use_bias=UB)(merge3)\n",
        "    merge2 = concatenate([conv2,deconv2], axis = 3)\n",
        "\n",
        "    deconv1 = Conv2DTranspose(64, (w,w), padding='same', activation=tf.nn.relu, strides=(2,2),use_bias=UB)(merge2)\n",
        "    merge1 = concatenate([conv1,deconv1], axis = 3)\n",
        "\n",
        "    conv_last = Conv2D(1, (w,w), padding='same', activation=tf.nn.relu,use_bias=UB)(merge1)\n",
        "\n",
        "    model = Model(inputs,conv_last)\n",
        "\n",
        "    model.compile(optimizer = keras.optimizers.Adam(learning_rate=0.00010), loss = \"mean_squared_error\", metrics = [\"accuracy\"])\n",
        "    \n",
        "    return model\n",
        "\n",
        "model = create_model()\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 save_freq = 250,\n",
        "                                                 verbose = 1)\n",
        "\n",
        "start_time = time.time()\n",
        "history = model.fit(X_training_blur, X_training, validation_data = (X_validation_blur, X_validation), epochs = Nepochs, batch_size = 32, callbacks=[cp_callback])\n",
        "\n",
        "training_time = time.time()-start_time\n",
        "\n",
        "# test and save on validation data\n",
        "X_val_blur = X_validation_blur\n",
        "X_val = X_validation\n",
        "# model.load_weights(checkpoint_path)\n",
        "start_time = time.time()\n",
        "predict = model.predict(X_val_blur)\n",
        "testing_time = time.time()-start_time\n",
        "dictionary = {}\n",
        "dictionary['results'] = {'input':X_val_blur, 'predictions':predict, 'validation':X_val}\n",
        "dictionary['time'] = {'training_time': training_time, 'testing_time': testing_time}\n",
        "\n",
        "sio.savemat(\"/content/gdrive/MyDrive/MPhys Project/centroid/run_27/results.mat\", dictionary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nDZ-SIEjOitN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2bf69de-f8b8-48de-e8f1-46a5284f19bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow==2.5.0 in /usr/local/lib/python3.9/dist-packages (2.5.0)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.5.0) (3.1.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.5.0) (1.12.1)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.5.0) (0.15.0)\n",
            "Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.5.0) (2.11.2)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.5.0) (1.1.2)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.5.0) (0.4.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.5.0) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.5.0) (3.3.0)\n",
            "Requirement already satisfied: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.5.0) (2.5.0.dev2021032900)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.5.0) (3.7.4.3)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.5.0) (1.15.0)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.5.0) (1.19.5)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.5.0) (1.12)\n",
            "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.5.0) (2.5.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.5.0) (3.19.6)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.5.0) (0.40.0)\n",
            "Requirement already satisfied: grpcio~=1.34.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.5.0) (1.34.1)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.5.0) (1.6.3)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.5.0) (0.2.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (2.2.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (1.8.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (67.6.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (3.4.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (2.16.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (0.6.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (2.27.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0) (5.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5.0) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow==2.5.0) (6.1.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.5->tensorflow==2.5.0) (2.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.5->tensorflow==2.5.0) (3.15.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5.0) (3.2.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras==2.4.3 in /usr/local/lib/python3.9/dist-packages (2.4.3)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.9/dist-packages (from keras==2.4.3) (1.10.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.9/dist-packages (from keras==2.4.3) (6.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.9/dist-packages (from keras==2.4.3) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.9/dist-packages (from keras==2.4.3) (1.19.5)\n",
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "Fri Mar 24 13:57:15 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    53W / 400W |   9477MiB / 40960MiB |      0%      Default |\n",
            "|                               |                      |             Disabled |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 48, 48, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 48, 48, 64)   1664        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 24, 24, 64)   0           conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 24, 24, 128)  204928      max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 12, 12, 128)  0           conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 12, 12, 256)  819456      max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 6, 6, 256)    0           conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 6, 6, 512)    3277312     max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 512)    0           conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 3, 3, 1024)   13108224    max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose (Conv2DTranspo (None, 6, 6, 512)    13107712    conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 6, 6, 1024)   0           conv2d_3[0][0]                   \n",
            "                                                                 conv2d_transpose[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTrans (None, 12, 12, 256)  6553856     concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 12, 12, 512)  0           conv2d_2[0][0]                   \n",
            "                                                                 conv2d_transpose_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTrans (None, 24, 24, 128)  1638528     concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 24, 24, 256)  0           conv2d_1[0][0]                   \n",
            "                                                                 conv2d_transpose_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_3 (Conv2DTrans (None, 48, 48, 64)   409664      concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 48, 48, 128)  0           conv2d[0][0]                     \n",
            "                                                                 conv2d_transpose_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 48, 48, 1)    3201        concatenate_3[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 39,124,545\n",
            "Trainable params: 39,124,545\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#install keras and tensorflow \n",
        "!pip install tensorflow==2.5.0\n",
        "!pip install keras==2.4.3\n",
        "\n",
        "\n",
        "# !pip install tensorflow==2.1.0\n",
        "# !pip install keras==2.2.4\n",
        "\n",
        "import os\n",
        "import time\n",
        "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" # Assign which GPU to run on, \"0\" or \"1\"\n",
        "import tensorflow as tf\n",
        "import scipy.io as sio\n",
        "from tensorflow import keras\n",
        "tf.keras.backend.clear_session()\n",
        "import numpy as np\n",
        "from tensorflow.python.keras.layers import Input, Dense, Conv2D, Conv2DTranspose, MaxPool2D, UpSampling2D, concatenate, Flatten, Reshape, Cropping2D\n",
        "from tensorflow.python.keras.models import Model\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "# !unzip \"/content/training_data.zip\" -d \"/content\"\n",
        "\n",
        "!nvidia-smi\n",
        "tf.test.gpu_device_name()\n",
        "\n",
        "\n",
        "Training_Dataset_path_centroid = \"/content/gdrive/MyDrive/MPhys Project/centroid/run_27/centroid.mat\"\n",
        "Training_Dataset_path_gaussfilt = \"/content/gdrive/MyDrive/MPhys Project/centroid/run_27/gaussfilt.mat\"\n",
        "checkpoint_path = \"/content/gdrive/MyDrive/MPhys Project/centroid/run_27\"\n",
        "\n",
        "\n",
        "Nepochs = 500\n",
        "\n",
        "X = sio.loadmat(Training_Dataset_path_centroid)\n",
        "X = X['images_sampled_mat']\n",
        "X = np.swapaxes(X, 0, -1)\n",
        "X = np.swapaxes(X, 1, 2)\n",
        "X = np.reshape(X, (X.shape[0], X.shape[1], X.shape[2], 1))\n",
        "\n",
        "X_blur = sio.loadmat(Training_Dataset_path_gaussfilt)\n",
        "X_blur = X_blur['images_gaussfilt_mat']\n",
        "\n",
        "X_blur = np.swapaxes(X_blur, 0, -1)\n",
        "X_blur = np.swapaxes(X_blur, 1, 2)\n",
        "X_blur = np.reshape(X_blur, (X.shape[0], X.shape[1], X.shape[2], 1))\n",
        "\n",
        "\n",
        "X = X[:1500]\n",
        "X_blur = X_blur[:1500]\n",
        "X_training = X[150:]\n",
        "X_training_blur = X_blur[150:]\n",
        "X_validation = X[:150]\n",
        "X_validation_blur = X_blur[:150]\n",
        "\n",
        "\n",
        "# model\n",
        "def create_model():\n",
        "    UB = True\n",
        "    w = 5\n",
        "    inputs = Input((48,48,1))\n",
        "    conv1 = Conv2D(64, (w,w), padding='same', activation=tf.nn.relu,use_bias=UB)(inputs)\n",
        "    pool1 = MaxPool2D((2,2), padding='same')(conv1)\n",
        "\n",
        "    conv2 = Conv2D(128, (w,w), padding='same', activation=tf.nn.relu,use_bias=UB)(pool1)\n",
        "    pool2 = MaxPool2D((2,2), padding='same')(conv2)\n",
        "\n",
        "    conv3 = Conv2D(256, (w,w), padding='same', activation=tf.nn.relu,use_bias=UB)(pool2)\n",
        "    pool3 = MaxPool2D((2,2), padding='same')(conv3)\n",
        "\n",
        "    conv4 = Conv2D(512, (w,w), padding='same', activation=tf.nn.relu,use_bias=UB)(pool3)\n",
        "    pool4 = MaxPool2D((2,2), padding='same')(conv4)\n",
        "\n",
        "    conv5 = Conv2D(1024, (w,w), padding='same', activation=tf.nn.relu,use_bias=UB)(pool4)\n",
        "\n",
        "\n",
        "    deconv4 = Conv2DTranspose(512, (w,w), padding='same', activation=tf.nn.relu, strides=(2,2),use_bias=UB)(conv5)\n",
        "    # cropped_decon4 = Cropping2D(cropping=((1, 0), (1, 0)))(deconv4)\n",
        "    # merge4 = concatenate([conv4,cropped_decon4], axis = 3)\n",
        "    merge4 = concatenate([conv4,deconv4], axis = 3)\n",
        "\n",
        "    deconv3 = Conv2DTranspose(256, (w,w), padding='same', activation=tf.nn.relu, strides=(2,2),use_bias=UB)(merge4)\n",
        "    # cropped_deconv3 = Cropping2D(cropping=((1, 0), (0, 0)))(deconv3)\n",
        "\n",
        "    # merge3 = concatenate([conv3,cropped_deconv3], axis = 3)\n",
        "    merge3 = concatenate([conv3,deconv3], axis = 3)\n",
        "\n",
        "\n",
        "    deconv2 = Conv2DTranspose(128, (w,w), padding='same', activation=tf.nn.relu, strides=(2,2),use_bias=UB)(merge3)\n",
        "    \n",
        "    merge2 = concatenate([conv2,deconv2], axis = 3)\n",
        "    deconv1 = Conv2DTranspose(64, (w,w), padding='same', activation=tf.nn.relu, strides=(2,2),use_bias=UB)(merge2)\n",
        "    merge1 = concatenate([conv1,deconv1], axis = 3)\n",
        "    conv_last = Conv2D(1, (w,w), padding='same', activation=tf.nn.relu,use_bias=UB)(merge1)\n",
        "\n",
        "    model = Model(inputs,conv_last)\n",
        "\n",
        "    model.compile(optimizer = keras.optimizers.Adam(learning_rate=0.00010), loss = \"mean_squared_error\", metrics = [\"accuracy\"])\n",
        "    # model.compile(optimizer = 'adam', loss = \"mean_squared_error\", metrics = [\"accuracy\"])\n",
        "\n",
        "    \n",
        "    return model\n",
        "\n",
        "model = create_model()\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 save_freq = 250,\n",
        "                                                 verbose = 1)\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Process_Dataset_path_gaussfilt = \"/content/gdrive/MyDrive/MPhys Project/centroid/run_28/10^5/gaussfilt_process.mat\"\n",
        "X_val_blur = sio.loadmat(Process_Dataset_path_gaussfilt)\n",
        "X_val_blur = X_val_blur['images_gaussfilt_mat']\n",
        "X_val_blur = np.swapaxes(X_val_blur, 0, -1)\n",
        "X_val_blur = np.swapaxes(X_val_blur, 1, 2)\n",
        "X_val_blur = np.reshape(X_val_blur, (X_val_blur.shape[0], X_val_blur.shape[1], X_val_blur.shape[2], 1))\n",
        "\n",
        "Process_Dataset_path_centroid = \"/content/gdrive/MyDrive/MPhys Project/centroid/run_28/10^1/centroid_process.mat\"\n",
        "X_val = sio.loadmat(Process_Dataset_path_centroid)\n",
        "X_val = X_val['images_sampled_mat']\n",
        "X_val = np.swapaxes(X_val, 0, -1)\n",
        "X_val = np.swapaxes(X_val, 1, 2)\n",
        "X_val = np.reshape(X_val, (X_val.shape[0], X_val.shape[1], X_val.shape[2], 1))\n",
        "\n",
        "model.load_weights(checkpoint_path)\n",
        "start_time = time.time()\n",
        "predict = model.predict(X_val_blur)\n",
        "testing_time = time.time()-start_time\n",
        "dictionary = {}\n",
        "dictionary['results'] = {'input':X_val_blur, 'predictions':predict, 'validation':X_val}\n",
        "# dictionary['time'] = {'training_time': training_time, 'testing_time': testing_time}\n",
        "\n",
        "sio.savemat(\"/content/gdrive/MyDrive/MPhys Project/centroid/run_28/10^1/results_process.mat\", dictionary)\n",
        "# sio.savemat(\"/content/gdrive/MyDrive/MPhys Project/run_15/history.mat\", history.history)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}